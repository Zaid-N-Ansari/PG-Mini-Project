{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f55d46",
   "metadata": {},
   "source": [
    "##   üè° Concrete Strength Prediction: From Exploration to Modeling üèóÔ∏è\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   1\\. üßê Project Initialization: Library Imports\n",
    "\n",
    "We begin by importing the necessary Python libraries. These tools will help us handle data, perform calculations, visualize information, build machine learning models, and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361447fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import log1p\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "scores = pd.DataFrame(columns=['Model', 'Train R¬≤', 'Test R¬≤', ' || Diff ||'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf265c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   2\\. üì• Data Loading and Inspection\n",
    "\n",
    "In this step, we load the concrete strength dataset from a CSV file. We then identify the features (input variables) and the target variable ('strength', which is what we want to predict). Finally, we display the first few rows of the data to get an initial look at its contents.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fe4d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.3</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>971.8</td>\n",
       "      <td>748.5</td>\n",
       "      <td>28</td>\n",
       "      <td>29.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>124.3</td>\n",
       "      <td>158.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1080.8</td>\n",
       "      <td>796.2</td>\n",
       "      <td>14</td>\n",
       "      <td>23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.7</td>\n",
       "      <td>187.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>956.9</td>\n",
       "      <td>861.2</td>\n",
       "      <td>28</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.8</td>\n",
       "      <td>183.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1047.4</td>\n",
       "      <td>696.7</td>\n",
       "      <td>28</td>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>28</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>531.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.8</td>\n",
       "      <td>28.2</td>\n",
       "      <td>852.1</td>\n",
       "      <td>893.7</td>\n",
       "      <td>3</td>\n",
       "      <td>41.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>55.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>7</td>\n",
       "      <td>52.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement   slag    ash  water  superplastic  coarseagg  fineagg  age  \\\n",
       "0      141.3  212.0    0.0  203.5           0.0      971.8    748.5   28   \n",
       "1      168.9   42.2  124.3  158.3          10.8     1080.8    796.2   14   \n",
       "2      250.0    0.0   95.7  187.4           5.5      956.9    861.2   28   \n",
       "3      266.0  114.0    0.0  228.0           0.0      932.0    670.0   28   \n",
       "4      154.8  183.4    0.0  193.3           9.1     1047.4    696.7   28   \n",
       "...      ...    ...    ...    ...           ...        ...      ...  ...   \n",
       "1025   135.0    0.0  166.0  180.0          10.0      961.0    805.0   28   \n",
       "1026   531.3    0.0    0.0  141.8          28.2      852.1    893.7    3   \n",
       "1027   276.4  116.0   90.3  179.6           8.9      870.1    768.3   28   \n",
       "1028   342.0   38.0    0.0  228.0           0.0      932.0    670.0  270   \n",
       "1029   540.0    0.0    0.0  173.0           0.0     1125.0    613.0    7   \n",
       "\n",
       "      strength  \n",
       "0        29.89  \n",
       "1        23.51  \n",
       "2        29.22  \n",
       "3        45.85  \n",
       "4        18.29  \n",
       "...        ...  \n",
       "1025     13.29  \n",
       "1026     41.30  \n",
       "1027     44.28  \n",
       "1028     55.06  \n",
       "1029     52.61  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Zaid-N-Ansari/PG-Mini-Project/refs/heads/main/Data/Concrete.csv')\n",
    "features = df.columns[:-1].tolist()\n",
    "target = 'strength'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6674c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   3\\. üìä Initial Data Exploration: Box Plots\n",
    "\n",
    "The following code was designed to create box plots. Box plots are a useful way to visualize the distribution of data and identify potential outliers (extreme values).\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7cdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25, 20))\n",
    "# plt.subplot(3, 3, 1)\n",
    "# plt.title('Box plot of features')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Value')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.boxplot([df[feature] for feature in features], labels=features, showfliers=True)\n",
    "# plt.show()\n",
    "\n",
    "# for feature in features:\n",
    "# \tplt.figure(figsize=(10, 5))\n",
    "# \tplt.boxplot(df[feature], showfliers=True, vert=False)\n",
    "# \tplt.title(f'Box plot of {feature}')\n",
    "# \tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55a058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.3</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>971.8</td>\n",
       "      <td>748.5</td>\n",
       "      <td>28</td>\n",
       "      <td>29.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>124.3</td>\n",
       "      <td>158.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1080.8</td>\n",
       "      <td>796.2</td>\n",
       "      <td>14</td>\n",
       "      <td>23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.7</td>\n",
       "      <td>187.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>956.9</td>\n",
       "      <td>861.2</td>\n",
       "      <td>28</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.8</td>\n",
       "      <td>183.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1047.4</td>\n",
       "      <td>696.7</td>\n",
       "      <td>28</td>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>28</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>531.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.8</td>\n",
       "      <td>28.2</td>\n",
       "      <td>852.1</td>\n",
       "      <td>893.7</td>\n",
       "      <td>3</td>\n",
       "      <td>41.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>342.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>55.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>7</td>\n",
       "      <td>52.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement   slag    ash  water  superplastic  coarseagg  fineagg  age  \\\n",
       "0      141.3  212.0    0.0  203.5           0.0      971.8    748.5   28   \n",
       "1      168.9   42.2  124.3  158.3          10.8     1080.8    796.2   14   \n",
       "2      250.0    0.0   95.7  187.4           5.5      956.9    861.2   28   \n",
       "3      266.0  114.0    0.0  228.0           0.0      932.0    670.0   28   \n",
       "4      154.8  183.4    0.0  193.3           9.1     1047.4    696.7   28   \n",
       "...      ...    ...    ...    ...           ...        ...      ...  ...   \n",
       "1025   135.0    0.0  166.0  180.0          10.0      961.0    805.0   28   \n",
       "1026   531.3    0.0    0.0  141.8          28.2      852.1    893.7    3   \n",
       "1027   276.4  116.0   90.3  179.6           8.9      870.1    768.3   28   \n",
       "1028   342.0   38.0    0.0  228.0           0.0      932.0    670.0  270   \n",
       "1029   540.0    0.0    0.0  173.0           0.0     1125.0    613.0    7   \n",
       "\n",
       "      strength  \n",
       "0        29.89  \n",
       "1        23.51  \n",
       "2        29.22  \n",
       "3        45.85  \n",
       "4        18.29  \n",
       "...        ...  \n",
       "1025     13.29  \n",
       "1026     41.30  \n",
       "1027     44.28  \n",
       "1028     55.06  \n",
       "1029     52.61  \n",
       "\n",
       "[998 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eise hi uncomment karna outlier treatment ke liye, sirf eise hi aur konsa bhi outliers treatment wala nhi\n",
    "    #    ^\n",
    "    #    |\n",
    "    #    |\n",
    "    #    |\n",
    "    #    |\n",
    "df = df[df['water'] < 240]\n",
    "df = df[df['superplastic'] < 30]\n",
    "df = df[df['fineagg'] < 960]\n",
    "df = df[df['age'] < 300]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c379be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   4\\. üìä Post-Outlier Removal Visualization\n",
    "\n",
    "This code would generate box plots *after* the outlier removal in the previous step. Comparing these plots to those in section 3 would show the impact of removing outliers.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746f959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25, 20))\n",
    "# plt.subplot(3, 3, 1)\n",
    "# plt.title('Box plot of features')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Value')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.boxplot([df[feature] for feature in features], labels=features, showfliers=True)\n",
    "# plt.show()\n",
    "\n",
    "# for feature in features:\n",
    "# \tplt.figure(figsize=(10, 5))\n",
    "# \tplt.boxplot(df[feature], showfliers=True, vert=False)\n",
    "# \tplt.title(f'Box plot of {feature}')\n",
    "# \tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f6268",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   5\\. üõ†Ô∏è Feature Transformation and Data Splitting\n",
    "\n",
    "This is a critical data preprocessing stage. First, we address skewness (asymmetry) in the data by applying a log transformation to features that exhibit high skewness.  Then, we split the data into training and testing sets. The training set is used to train the models, and the testing set is used to evaluate their performance on unseen data. Finally, we scale the numerical features using `StandardScaler`. Scaling ensures that all features contribute equally to the models.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8bf847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_skewed_features = df[features].skew()[abs(df[features].skew()) > 0.5].index\n",
    "\n",
    "for feature in highly_skewed_features:\n",
    "    df[feature] = log1p(df[feature])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d001c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   6\\. üìä Post-Transformation Visualization (Commented Out)\n",
    "\n",
    "This commented-out section would visualize the feature distributions *after* the log transformation, allowing us to see how the transformation affected the skewness.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf04c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25, 20))\n",
    "# plt.subplot(3, 3, 1)\n",
    "# plt.title('Box plot of features')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Value')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.boxplot([df[feature] for feature in features], labels=features, showfliers=True)\n",
    "# plt.show()\n",
    "\n",
    "# for feature in features:\n",
    "# \tplt.figure(figsize=(10, 5))\n",
    "# \tplt.boxplot(df[feature], showfliers=True, vert=False)\n",
    "# \tplt.title(f'Box plot of {feature}')\n",
    "# \tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ebbbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   8\\. ü§ñ Linear Regression Model\n",
    "\n",
    "Here, we train a Linear Regression model. We then evaluate its performance using the R-squared metric, which measures how well the model fits the data. We calculate the R-squared on both the training and testing sets to check for overfitting (when the model performs much better on the training data than on the testing data).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36b40e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>|| Diff ||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>81.327857</td>\n",
       "      <td>81.82655</td>\n",
       "      <td>0.498694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model   Train R¬≤   Test R¬≤   || Diff ||\n",
       "1  Linear Regression  81.327857  81.82655     0.498694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(x_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(x_test)\n",
    "y_train_pred = LR.predict(x_train)\n",
    "\n",
    "training_r2 = LR.score(x_train, y_train) * 100\n",
    "testing_r2 = LR.score(x_test, y_test) * 100\n",
    "\n",
    "diff = abs(training_r2 - testing_r2)\n",
    "\n",
    "# pd.DataFrame({'Model': 'Linear Regression', 'Traning R2': training_r2, 'Testing R2': testing_r2, 'Traning and Testing R2 Diff': diff}, index=[1])\n",
    "scores.loc[1] = ['Linear Regression', training_r2, testing_r2, diff]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741cd57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   9\\. üå≥ Decision Tree Regressor\n",
    "\n",
    "This section trains and evaluates a Decision Tree Regressor. <br>\n",
    "Hyperparameters (parameters that control the model's structure) such as `ccp_alpha`, `max_depth`, `max_leaf_nodes`, and `min_samples_split` are set to influence the tree's complexity.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c97998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>|| Diff ||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>81.327857</td>\n",
       "      <td>81.826550</td>\n",
       "      <td>0.498694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>84.038220</td>\n",
       "      <td>75.545258</td>\n",
       "      <td>8.492962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   Train R¬≤    Test R¬≤   || Diff ||\n",
       "1         Linear Regression  81.327857  81.826550     0.498694\n",
       "2  Decision Tree Regression  84.038220  75.545258     8.492962"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR = DecisionTreeRegressor(ccp_alpha=0.689, max_depth=80, max_leaf_nodes=87, min_samples_split=26, max_features=4)\n",
    "\n",
    "DTR.fit(x_train, y_train)\n",
    "\n",
    "y_pred = DTR.predict(x_test)\n",
    "y_train_pred = DTR.predict(x_train)\n",
    "\n",
    "training_r2 = DTR.score(x_train, y_train) * 100\n",
    "testing_r2 = DTR.score(x_test, y_test) * 100\n",
    "\n",
    "diff = abs(training_r2 - testing_r2)\n",
    "\n",
    "scores.loc[2] = ['Decision Tree Regression', training_r2, testing_r2, diff]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4886df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   10\\. üå≤ Random Forest and XGBoost Regressors\n",
    "\n",
    "This part explores more advanced models: Random Forest and XGBoost. <br>\n",
    "These are ensemble methods, which combine multiple simpler models to make more accurate predictions. Hyperparameters are again used to tune the models.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28893e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>|| Diff ||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>81.327857</td>\n",
       "      <td>81.826550</td>\n",
       "      <td>0.498694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>84.038220</td>\n",
       "      <td>75.545258</td>\n",
       "      <td>8.492962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>88.078543</td>\n",
       "      <td>85.199930</td>\n",
       "      <td>2.878613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   Train R¬≤    Test R¬≤   || Diff ||\n",
       "1         Linear Regression  81.327857  81.826550     0.498694\n",
       "2  Decision Tree Regression  84.038220  75.545258     8.492962\n",
       "3  Random Forest Regression  88.078543  85.199930     2.878613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR = RandomForestRegressor(n_estimators=825, min_samples_split=8, min_samples_leaf=8, max_features=0.49, bootstrap=True, oob_score=True)\n",
    "\n",
    "RFR.fit(x_train, y_train)\n",
    "\n",
    "y_pred = RFR.predict(x_test)\n",
    "y_train_pred = RFR.predict(x_train)\n",
    "\n",
    "training_r2 = RFR.score(x_train, y_train) * 100\n",
    "testing_r2 = RFR.score(x_test, y_test) * 100\n",
    "\n",
    "diff = abs(training_r2 - testing_r2)\n",
    "\n",
    "scores.loc[3] = ['Random Forest Regression', training_r2, testing_r2, diff]\n",
    "scores\n",
    "\n",
    "# XGB = XGBRegressor(n_estimators=354, learning_rate=0.009, max_depth=6, gamma=0.15, subsample=0.045, colsample_bytree=0.8)\n",
    "# XGB.fit(x_train, y_train)\n",
    "\n",
    "# y_pred = XGB.predict(x_test)\n",
    "# y_train_pred = XGB.predict(x_train)\n",
    "# training_r2 = XGB.score(x_train, y_train) * 100\n",
    "# testing_r2 = XGB.score(x_test, y_test) * 100\n",
    "# diff = abs(training_r2 - testing_r2)\n",
    "# print(training_r2, testing_r2, diff, 1-diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7fe83",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   12\\. ‚öôÔ∏è Support Vector Regression (SVR)\n",
    "\n",
    "This part demonstrates training and evaluating a Support Vector Regression (SVR) model. SVR is another powerful regression technique. <br>\n",
    "Hyperparameters like `C`, `gamma`, and `epsilon` are tuned to control the model's behavior.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b56a368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>|| Diff ||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>81.327857</td>\n",
       "      <td>81.826550</td>\n",
       "      <td>0.498694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>84.038220</td>\n",
       "      <td>75.545258</td>\n",
       "      <td>8.492962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>88.078543</td>\n",
       "      <td>85.199930</td>\n",
       "      <td>2.878613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>88.213014</td>\n",
       "      <td>87.681997</td>\n",
       "      <td>0.531017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model   Train R¬≤    Test R¬≤   || Diff ||\n",
       "1          Linear Regression  81.327857  81.826550     0.498694\n",
       "2   Decision Tree Regression  84.038220  75.545258     8.492962\n",
       "3   Random Forest Regression  88.078543  85.199930     2.878613\n",
       "4  Support Vector Regression  88.213014  87.681997     0.531017"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVR(C=410, gamma=0.01, epsilon=0.06)\n",
    "\n",
    "SVM.fit(x_train, y_train)\n",
    "\n",
    "y_pred = SVM.predict(x_test)\n",
    "y_train_pred = SVM.predict(x_train)\n",
    "\n",
    "training_r2 = SVM.score(x_train, y_train) * 100\n",
    "testing_r2 = SVM.score(x_test, y_test) * 100\n",
    "\n",
    "diff = abs(training_r2 - testing_r2)\n",
    "\n",
    "scores.loc[4] = ['Support Vector Regression', training_r2, testing_r2, diff]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb9d73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "##   13\\. üëØ‚Äç‚ôÄÔ∏è K-Nearest Neighbors (KNN)\n",
    "\n",
    "<li>This final section repeats the training and evaluation of KNN.\n",
    "<li> Comparing the results from different runs is essential for model selection.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a0c6e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>|| Diff ||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>81.327857</td>\n",
       "      <td>81.826550</td>\n",
       "      <td>0.498694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>84.038220</td>\n",
       "      <td>75.545258</td>\n",
       "      <td>8.492962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>88.078543</td>\n",
       "      <td>85.199930</td>\n",
       "      <td>2.878613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>88.213014</td>\n",
       "      <td>87.681997</td>\n",
       "      <td>0.531017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors Regression</td>\n",
       "      <td>81.423613</td>\n",
       "      <td>80.158281</td>\n",
       "      <td>1.265333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model   Train R¬≤    Test R¬≤   || Diff ||\n",
       "1               Linear Regression  81.327857  81.826550     0.498694\n",
       "2        Decision Tree Regression  84.038220  75.545258     8.492962\n",
       "3        Random Forest Regression  88.078543  85.199930     2.878613\n",
       "4       Support Vector Regression  88.213014  87.681997     0.531017\n",
       "5  K-Nearest Neighbors Regression  81.423613  80.158281     1.265333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsRegressor(algorithm='auto', metric='minkowski', p=2, leaf_size=65, n_neighbors=15)\n",
    "\n",
    "KNN.fit(x_train, y_train)\n",
    "\n",
    "y_pred = KNN.predict(x_test)\n",
    "y_train_pred = KNN.predict(x_train)\n",
    "\n",
    "training_r2 = KNN.score(x_train, y_train) * 100\n",
    "testing_r2 = KNN.score(x_test, y_test) * 100\n",
    "\n",
    "diff = abs(training_r2 - testing_r2)\n",
    "\n",
    "scores.loc[5] = ['K-Nearest Neighbors Regression', training_r2, testing_r2, diff]\n",
    "scores\n",
    "\n",
    "# XGB = XGBRegressor(n_estimators=354, learning_rate=0.0099, max_depth=6, gamma=0.12, subsample=0.045, colsample_bytree=0.8)\n",
    "# XGB.fit(x_train, y_train)\n",
    "\n",
    "# y_pred = XGB.predict(x_test)\n",
    "# y_train_pred = XGB.predict(x_train)\n",
    "# training_r2 = XGB.score(x_train, y_train) * 100\n",
    "# testing_r2 = XGB.score(x_test, y_test) * 100\n",
    "# diff = abs(training_r2 - testing_r2)\n",
    "# print(training_r2, testing_r2, diff, 1-diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908df728",
   "metadata": {},
   "source": [
    "### üìä **Model Evaluation Summary**\n",
    "\n",
    "| Model | Train R¬≤ | Test R¬≤ | Absolute Difference |\n",
    "|----------------------|----------|---------|------------|\n",
    "| Linear Regression | 81.328% |\t81.826% | 0.498 |\n",
    "| Decision Tree Regression | 83.991 | 76.276 | 7.715 |\n",
    "| Random Forest Regression | 87.964 | 85.152 | 2.812 |\n",
    "| Support Vector Regression | 88.213 | 87.682 | 0.531 |\n",
    "| K-Nearest Neighbors Regression | 81.424 | 80.158 | 1.266 |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† **Inference**\n",
    "\n",
    "- üîπ **Linear Regression** shows good generalization with a small gap between training and test R¬≤.\n",
    "- üå≥ **Decision Tree** performs well on training data but has a larger drop on test data, indicating **overfitting**.\n",
    "- üå≤ **Random Forest** balances high performance with improved generalization over a single tree ‚Äî a **robust** model.\n",
    "- üìà **Support Vector Regressor (SVR)** maintains consistent R¬≤ scores, indicating **stable generalization**.\n",
    "- üë• **K-Nearest Neighbors** performs decently but might be sensitive to data scaling and choice of `k`.\n",
    "\n",
    "> üìå **Conclusion**:  \n",
    "> ‚úÖ **Random Forest** emerges as the most balanced model ‚Äî high training performance and strong generalization.  \n",
    "> ‚ö†Ô∏è **Decision Tree** may need pruning or parameter tuning to avoid overfitting.  \n",
    "> üí° Consider **SVR or Linear Regression** if interpretability and consistency are key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c48dd",
   "metadata": {},
   "source": [
    "## üîç Feature Characteristics & Insights\n",
    "\n",
    "### üìà Strong correlation expected:\n",
    "- **Cement and Age** usually have positive correlation with strength.\n",
    "- **Too much Water** typically shows negative correlation (weakens concrete).\n",
    "- **Superplasticizer** often helps improve strength by reducing water demand.\n",
    "\n",
    "### üßÆ Mostly numerical:\n",
    "- All features are continuous, which makes them ideal for regression models.\n",
    "\n",
    "### üîÑ Some nonlinear relationships:\n",
    "- e.g., **Age vs Strength** curve tends to flatten over time ‚Äî this is why models like **SVR** and **Random Forest** do better than pure **Linear Regression**.\n",
    "\n",
    "### üìâ Multicollinearity may exist:\n",
    "- **Cement**, **slag**, and **fly ash** might substitute each other ‚Äî linear models might suffer slightly unless regularization is used.\n",
    "\n",
    "## ü§ñ Why Models Performed as They Did\n",
    "- **SVR** and **Random Forest** performed best because they capture non-linear and complex interactions.\n",
    "- **Decision Tree** overfitted likely due to lack of regularization.\n",
    "- **Linear Regression** did okay because the dataset still holds some linear structure.\n",
    "- **KNN** did fairly well but may suffer when feature distributions vary widely (e.g., Cement vs Superplasticizer values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafc4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
